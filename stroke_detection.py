# -*- coding: utf-8 -*-
"""Stroke_Detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d43REeqkCMrSJmRQVxcWTUad8O_z9WmS
"""

import subprocess

process = subprocess.Popen(["python", "-c", "import imbalanced_learn; print(imbalanced_learn.__file__)"], stdout=subprocess.PIPE)
output, err = process.communicate()

if err:
    print("Error:", err)
else:
    print("imbalanced_learn.__file__:", output.decode("utf-8").strip())

rm -rf <path_to_imblearn_dir>

import subprocess

process = subprocess.Popen(["python", "-c", "import sklearn; print(sklearn.__file__)"], stdout=subprocess.PIPE)
output, err = process.communicate()

if err:
    print("Error:", err)
else:
    print("sklearn.__file__:", output.decode("utf-8").strip())

rm -rf <path_to_sklearn_dir>

!pip cache purge

!pip install scikit-learn
!pip install imblearn

cd /content/drive/MyDrive/StrokeProject

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as ms
import sklearn

train = pd.read_csv('train_2v.csv')
test = pd.read_csv('test_2v.csv')
train.head()

"""In the dataset we have 12 columns where 11 contains the features and the last one contains the result


"""

test.head()

train.shape

test.shape

"""**Data Cleaning**
Identifing missing *attributes*
"""

train_missing_values=train.isnull().sum()
train_missing_values

test_missing_values=test.isnull().sum()
test_missing_values

ms.matrix(train)

"""Removing missing value


"""

train_data=train.dropna(axis=0,how="any")
test_data=test.dropna(axis=0,how="any")
print('train data shape: {}' .format(train_data.shape))
print('test data shape: {}' .format(test_data.shape))

ms.matrix(train_data)

ms.matrix(test_data)

"""Pattern Recognition"""

train_data["stroke"].value_counts()

sns.countplot(x=train_data["stroke"])
plt.title("no of patients affected by stroke", fontsize=15)
plt.show()

sns.countplot(x=train_data["gender"], hue=train_data["stroke"])
plt.title("gender vs stroke", fontsize=15)
plt.show()

train_data.groupby(["gender"])["stroke"].value_counts()

train_data["smoking_status"].value_counts()

train_data.groupby(["smoking_status"])["stroke"].value_counts()

sns.countplot(x=train_data["gender"], hue=train_data["smoking_status"])
plt.title("gender vs type of smokers", fontsize=15)
plt.show()

"""Encoding data"""

str_data=train_data.select_dtypes(include=['object'])
str_dt=test_data.select_dtypes(include=['object'])

int_data=train_data.select_dtypes(include=['integer', 'float'])
int_dt=test_data.select_dtypes(include=['integer', 'float'])

from sklearn.preprocessing import LabelEncoder

label=LabelEncoder()
features=str_data.apply(label.fit_transform)
features=features.join(int_data)
features.head()

test1=str_dt.apply(label.fit_transform)
Test=test1.join(int_dt)
Test.head()

"""# Modeling & predicting the **data**"""

xtrain=features.drop(["stroke"],axis=1)
xtrain.shape

ytrain=features["stroke"]
ytrain.head()
ytrain.shape

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test=train_test_split(xtrain, ytrain)

x_test.shape

y_test.shape

x_train.head()

y_train.head()

"""**Naive Bayes**"""

x_test.head()

y_test.head()

from sklearn.naive_bayes import GaussianNB

model=GaussianNB()
model.fit(x_train, y_train)

predict=model.predict(x_test)
predict

test_score=model.score(x_test, y_test)
print("NBtest_score:", test_score)

nb_conf_mtr=pd.crosstab(y_test, predict)
nb_conf_mtr

from sklearn.metrics import classification_report

nbreport=classification_report(y_test, predict)
print(nbreport)

"""**Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier

dt_mod=DecisionTreeClassifier(max_depth=8)
dt_mod.fit(x_train, y_train)

y_predict=dt_mod.predict(x_test)
y_predict

ts_dt_score=dt_mod.score(x_test, y_test)
print("Decision tree test score:", ts_dt_score)

dectree_report=classification_report(y_test, y_predict)
print(dectree_report)

dt_conf_mtr=pd.crosstab(y_test, y_predict)
dt_conf_mtr

"""**Random Forest**"""

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators= 100)

rfc.fit(x_train,y_train)

y_pred_rfc = rfc.predict(x_test)

print(classification_report(y_test,y_pred_rfc))

frst_cnf= pd.crosstab(y_test,y_pred_rfc)
print(frst_cnf)

"""**Multi-Layer Perceptron Classifier**"""

from sklearn.neural_network import MLPClassifier

mlp=MLPClassifier()

mlp.fit(x_train,y_train)

y_pred_mlp = mlp.predict(x_test)

mlp.score(x_test,y_test)

from sklearn.model_selection import cross_val_score
cross_val_score(model,xtrain,ytrain,cv = 20, scoring='accuracy').mean()

cross_val_score(dt_mod,xtrain,ytrain,cv = 20, scoring='accuracy').mean()

cross_val_score(rfc,xtrain,ytrain,cv = 20, scoring='accuracy').mean()

cross_val_score(mlp,xtrain,ytrain,cv = 20, scoring='accuracy').mean()

"""**Applying PCA**"""

from sklearn.decomposition import PCA
pca = PCA(n_components=3)
principalComponents = pca.fit_transform(xtrain)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test=train_test_split(xtrain, ytrain)

model_2=GaussianNB()
model_2.fit(x_train, y_train)

test_score=model_2.score(x_test, y_test)
print("NBtest_score:", test_score)

dt_mod=DecisionTreeClassifier()
dt_mod.fit(x_train, y_train)

ts_dt_score=dt_mod.score(x_test, y_test)
print("Decision tree test score:", ts_dt_score)

rfc.fit(x_train,y_train)

y_pred_rfc = rfc.predict(x_test)

print(pd.crosstab(y_test,y_pred_rfc))
print(classification_report(y_test,y_pred_rfc))

rfc.score(x_test,y_test)

mlp=MLPClassifier()

mlp.fit(x_train,y_train)

y_pred_mlp = mlp.predict(x_test)

mlp.score(x_test,y_test)

cross_val_score(model_2,xtrain,ytrain,cv = 20, scoring='accuracy').mean()

cross_val_score(dt_mod,xtrain,ytrain,cv = 20, scoring='accuracy').mean()

cross_val_score(rfc,xtrain,ytrain,cv = 20, scoring='accuracy').mean()

cross_val_score(mlp,xtrain,ytrain,cv = 20, scoring='accuracy').mean()